# -*- coding: utf-8 -*-
"""FaceRecognition_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bvp6zVb3hl1wJ4Wz3xAf5IewOS7ficcs
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow mtcnn scikit-learn tensorflow_hub
!pip install lz4

import os
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
from mtcnn import MTCNN
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import cv2
import random
import pickle
import tarfile
import requests
from tqdm.notebook import tqdm # adds progress bars
from google.colab import drive

import kagglehub

# Download latest version
path = kagglehub.dataset_download("jessicali9530/lfw-dataset")

print("Path to dataset files:", path)

import shutil
import os

# Define the destination directory in Google Drive
drive_dataset_path = "/content/drive/MyDrive/lfw_dataset"  # Change this to your desired path

# Copy the dataset to Google Drive
shutil.copytree(path, drive_dataset_path)

print(f"Dataset copied to Google Drive at: {drive_dataset_path}")

class FaceRecognitionSystem :
  def __init__(self) :
    self.detector = MTCNN()
    self.required_size = (160, 160)
    # efficientnet model
    self.facenet_model_layer = hub.KerasLayer("https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2")
    self.labels = []
    self.embeddings = []
    self.le = LabelEncoder()
    self.classifier = SVC(kernel = 'linear', C = 0.1, probability = True)

  def extract_face(self, image) :
    faces = self.detector.detect_faces(image)
    if not faces :
      return None
    x1, y1, w, h = faces[0]['box']
    x2, y2 = x1 + w, y1 + h
    face = image[y1:y2, x1:x2]
    face = cv2.resize(face, self.required_size)
    return face

  def _get_embedding(self, face) :
    # preprocess
    face = face.astype('float32') / 255.0
    face = (face-0.5)*2  # range [-1, 1]
    face_tensor = tf.convert_to_tensor([face])
    embedding = self.facenet_model_layer(face_tensor)
    return embedding.numpy()[0]

  def process_data(self, dataset_path, max_samples_per_person = 50) :
    person_samples = {}
    for person_name in os.listdir(dataset_path) :
      person_dir = os.path.join(dataset_path, person_name)
      if os.path.isdir(person_dir) :
        person_images = [f for f in os.listdir(person_dir)
                          if f.endswith(('.jpg', '.jpeg', '.png'))]
        if len(person_images) >= max_samples_per_person :
          person_images = random.sample(person_images, max_samples_per_person)
          person_samples[person_name] = person_images

    print(len(person_samples))
    # process faces for each eligible person
    for person_name, images in tqdm(person_samples.items(), desc = 'Processing faces') :
      successful_embeddings = 0
      for image in images :
        try :
          image_path = os.path.join(dataset_path, person_name, image)
          img = cv2.imread(image_path)
          img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
          face = self.extract_face(img)
          if face is not None :
            embedding = self._get_embedding(face)
            self.embeddings.append(embedding)
            self.labels.append(person_name)
            successful_embeddings += 1
        except Exception as e :
          print(f"Error Processing {image_path} : {str(e)}")

      print(f"Processed {successful_embeddings} images for {person_name}")

  def train_classifier(self) :
    if (len(self.embeddings) == 0) :
      print("No embeddings to train classifier")
      return None

    X = self.embeddings
    y = self.le.fit_transform(self.labels)

    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

    self.classifier.fit(xtrain, ytrain)
    ypred = self.classifier.predict(xtest)
    accuracy = accuracy_score(ytest, ypred)

    return {'xtrain' : xtrain,
            'xtest' : xtest,
            'ytrain' : ytrain,
            'ytest' : ytest,
            'ypred' : ypred,
            'accuracy' : accuracy}

def plot_results(results) :
  if results is None :
    print("No results to plot")
    return None

  plt.figure(figsize = (15, 5))
  plt.subplot(1, 2, 1)
  plt.title('Training Data Distribution')
  unique, counts = np.unique(results['ytrain'], return_counts = True)
  plt.bar(unique[:10], counts[:10])
  plt.xlabel('Class')
  plt.ylabel('Count')

  plt.subplot(1, 2, 2)
  plt.title(f'Model Accuracy : {results["accuracy"] : .2%}')
  cm = tf.math.confusion_matrix(results['ytest'], results['ypred'])
  plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Blues)
  plt.colorbar()
  plt.xlabel('Predicted label')
  plt.ylabel('True label')
  plt.tight_layout()
  plt.show()


try :
  # initialize system and process dataset
  face_system = FaceRecognitionSystem()
  dataset_path = "/content/drive/MyDrive/lfw_dataset/lfw-deepfunneled/lfw-deepfunneled"
  face_system.process_data(dataset_path)

  # train classifier
  results = face_system.train_classifier()

  if results is not None :
    plot_results(results)

    y_true = face_system.le.inverse_transform(results['ytest'])
    y_pred = face_system.le.inverse_transform(results['ypred'])
    print("\n",classification_report(y_true, y_pred))

    # save model
    save_path = '/content/drive/MyDrive/face_recognition_model.pkl'
    # Ensure the directory exists
    save_dir = os.path.dirname(save_path)
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    model_data = {
        'classifier' : face_system.classifier,
        'label_encoder' : face_system.le
    }
    with open(save_path, 'wb') as f:
      pickle.dump(model_data, f)
    print(f'Model saved to google drive : {save_path}')

  else :
    print(f"Training failed due to lack of data")

except Exception as e :
  print(f"An error occurred : {str(e)}")
  raise

"""__<font size = 4 color = 'green'>Visualization__"""

model_path = '/content/drive/MyDrive/face_recognition_model.pkl'

class FaceRecognitionDemo :
  def __init__(self, model_path) :
    with open(model_path, 'rb') as f :
      model = pickle.load(f)

    self.classifier = model['classifier']
    self.le = model['label_encoder']
    self.detector = MTCNN()
    self.facenet_model_layer = hub.KerasLayer("https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2")
    self.required_size = (160, 160)

  def process_image(self, image) :
    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    faces = self.detector.detect_faces(image)
    if not faces :
      return None, None

    x1, y1, w, h = faces[0]['box']
    x2, y2 = x1 + w, y1 + h

    face = rgb[y1 : y2, x1 : x2]
    face = cv2.resize(face, self.required_size)

    face = face.astype('float32') / 255.0
    face = (face-0.5)*2  # range [-1, 1]
    face_tensor = tf.convert_to_tensor([face])
    embedding = self.facenet_model_layer(face_tensor)
    embedding_np = embedding.numpy()[0]

    return embedding_np, (x1, y1, x2, y2)

  def predict(self, image) :
    embedding, box = self.process_image(image)
    if embedding is None :
      return None, None, None

    prob = self.classifier.predict_proba([embedding])[0]
    pred_class = np.argmax(prob)
    pred_name = self.le.inverse_transform([pred_class])[0]
    confidence = prob[pred_class]

    return pred_name, confidence, box

dataset_path = "/content/drive/MyDrive/lfw_dataset/lfw-deepfunneled/lfw-deepfunneled"

def get_random_test_images(lfw_path, num_images = 5) :
  selected = []
  # checking for images in which model is trained
  for person_name in os.listdir(lfw_path) :
      person_dir = os.path.join(lfw_path, person_name)
      if os.path.isdir(person_dir) :
        person_images = [f for f in os.listdir(person_dir)
                          if f.endswith(('.jpg', '.jpeg', '.png'))]
        if len(person_images) >= 50 :
          selected.append(person_name)

  selected = random.sample(selected, num_images)

  test_images = []

  for person in selected :
    person_dir = os.path.join(lfw_path, person)
    images = os.listdir(person_dir)
    img = random.choice(images)
    img_path = os.path.join(person_dir, img)
    img_arr = cv2.imread(img_path)
    test_images.append((person, img_arr))

  return test_images

def display_results(test_imgs, predictions) :
  plt.figure(figsize = (20, 4))
  for i, ((true_label, image), (pred_label, confidence, box)) in enumerate(zip(test_imgs, predictions)):
    plt.subplot(1, len(test_imgs), i + 1)
    rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    if box :
      x1, y1, x2, y2 = box
      cv2.rectangle(rgb_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    plt.imshow(rgb_img)
    plt.axis('off')
    if pred_label is None :
      result_txt = f"True:{true_label}\nNo face detected..."
    else :
      result_txt = f"True:{true_label}\nPred:{pred_label}\nConf:{confidence : .2%}"
    plt.title(result_txt, fontsize = 10)
  plt.tight_layout()
  plt.show()

try :
  drive.mount('/content/drive')
  print(f"Initializing Model ...\n")
  model = FaceRecognitionDemo(model_path)

  print(f"Getting test images ready...\n")
  test_images = get_random_test_images(dataset_path)

  print(f"Making Predictions ...\n")
  predictions = []
  for _, img in test_images :
    pred_label, confidence, box = model.predict(img)
    predictions.append((pred_label, confidence, box))

  print(f"Displaying Results ...\n")
  display_results(test_images, predictions)

  for (t,_), (p, confidence,_) in zip(test_images, predictions) :
    if p is not None :
      if t == p :
        print(f"✓ True : {t:<20} Predicted : {p:<20} Confidence : {confidence : .2%}")
      else :
        print(f"✗ True : {t:<20} Predicted : {p:<20} Confidence : {confidence : .2%}")

    else :
      print(f"✗ True : {t:<20} No face Detected")

except Exception as e :
  print(f"An error occurred : {str(e)}")
  raise

"""__<font size = 4>Trying Random Forest as Classifier__"""

from sklearn.ensemble import RandomForestClassifier

# trying random forest
class FaceRecognitionSystem2 :
  def __init__(self) :
    self.detector = MTCNN()
    self.required_size = (160, 160)
    # efficientnet model
    self.facenet_model_layer = hub.KerasLayer("https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2")
    self.labels = []
    self.embeddings = []
    self.le = LabelEncoder()
    self.classifier = RandomForestClassifier(bootstrap = True, n_jobs = -1)

  def extract_face(self, image) :
    faces = self.detector.detect_faces(image)
    if not faces :
      return None
    x1, y1, w, h = faces[0]['box']
    x2, y2 = x1 + w, y1 + h
    face = image[y1:y2, x1:x2]
    face = cv2.resize(face, self.required_size)
    return face

  def _get_embedding(self, face) :
    # preprocess
    face = face.astype('float32') / 255.0
    face = (face-0.5)*2  # range [-1, 1]
    face_tensor = tf.convert_to_tensor([face])
    embedding = self.facenet_model_layer(face_tensor)
    return embedding.numpy()[0]

  def process_data(self, dataset_path, max_samples_per_person = 50) :
    person_samples = {}
    for person_name in os.listdir(dataset_path) :
      person_dir = os.path.join(dataset_path, person_name)
      if os.path.isdir(person_dir) :
        person_images = [f for f in os.listdir(person_dir)
                          if f.endswith(('.jpg', '.jpeg', '.png'))]
        if len(person_images) >= max_samples_per_person :
          person_images = random.sample(person_images, max_samples_per_person)
          person_samples[person_name] = person_images

    print(len(person_samples))
    # process faces for each eligible person
    for person_name, images in tqdm(person_samples.items(), desc = 'Processing faces') :
      successful_embeddings = 0
      for image in images :
        try :
          image_path = os.path.join(dataset_path, person_name, image)
          img = cv2.imread(image_path)
          img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
          face = self.extract_face(img)
          if face is not None :
            embedding = self._get_embedding(face)
            self.embeddings.append(embedding)
            self.labels.append(person_name)
            successful_embeddings += 1
        except Exception as e :
          print(f"Error Processing {image_path} : {str(e)}")

      print(f"Processed {successful_embeddings} images for {person_name}")

  def train_classifier(self) :
    if (len(self.embeddings) == 0) :
      print("No embeddings to train classifier")
      return None

    X = self.embeddings
    y = self.le.fit_transform(self.labels)

    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

    self.classifier.fit(xtrain, ytrain)
    ypred = self.classifier.predict(xtest)
    accuracy = accuracy_score(ytest, ypred)

    return {'xtrain' : xtrain,
            'xtest' : xtest,
            'ytrain' : ytrain,
            'ytest' : ytest,
            'ypred' : ypred,
            'accuracy' : accuracy}

def plot_results2(results) :
  if results is None :
    print("No results to plot")
    return None

  plt.figure(figsize = (15, 5))
  plt.subplot(1, 2, 1)
  plt.title('Training Data Distribution')
  unique, counts = np.unique(results['ytrain'], return_counts = True)
  plt.bar(unique[:10], counts[:10])
  plt.xlabel('Class')
  plt.ylabel('Count')

  plt.subplot(1, 2, 2)
  plt.title(f'Model Accuracy : {results["accuracy"] : .2%}')
  cm = tf.math.confusion_matrix(results['ytest'], results['ypred'])
  plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Blues)
  plt.colorbar()
  plt.xlabel('Predicted label')
  plt.ylabel('True label')
  plt.tight_layout()
  plt.show()

try :
  # initialize system and process dataset
  face_system = FaceRecognitionSystem2()
  dataset_path = "/content/drive/MyDrive/lfw_dataset/lfw-deepfunneled/lfw-deepfunneled"
  face_system.process_data(dataset_path)

  # train classifier
  results = face_system.train_classifier()

  if results is not None :
    plot_results(results)

    y_true = face_system.le.inverse_transform(results['ytest'])
    y_pred = face_system.le.inverse_transform(results['ypred'])
    print("\n",classification_report(y_true, y_pred))

    # save model
    save_path = '/content/drive/MyDrive/face_recognition_model2.pkl'
    # Ensure the directory exists
    save_dir = os.path.dirname(save_path)
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    model_data = {
        'classifier' : face_system.classifier,
        'label_encoder' : face_system.le
    }
    with open(save_path, 'wb') as f:
      pickle.dump(model_data, f)
    print(f'Model saved to google drive : {save_path}')

  else :
    print(f"Training failed due to lack of data")

except Exception as e :
  print(f"An error occurred : {str(e)}")
  raise

class FaceRecognitionDemo2 :
  def __init__(self, model_path) :
    with open(model_path, 'rb') as f :
      model = pickle.load(f)

    self.classifier = model['classifier']
    self.le = model['label_encoder']
    self.detector = MTCNN()
    self.facenet_model_layer = hub.KerasLayer("https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2")
    self.required_size = (160, 160)

  def process_image(self, image) :
    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    faces = self.detector.detect_faces(image)
    if not faces :
      return None, None

    x1, y1, w, h = faces[0]['box']
    x2, y2 = x1 + w, y1 + h

    face = rgb[y1 : y2, x1 : x2]
    face = cv2.resize(face, self.required_size)

    face = face.astype('float32') / 255.0
    face = (face-0.5)*2  # range [-1, 1]
    face_tensor = tf.convert_to_tensor([face])
    embedding = self.facenet_model_layer(face_tensor)
    embedding_np = embedding.numpy()[0]

    return embedding_np, (x1, y1, x2, y2)

  def predict(self, image) :
    embedding, box = self.process_image(image)
    if embedding is None :
      return None, None, None

    prob = self.classifier.predict_proba([embedding])[0]
    pred_class = np.argmax(prob)
    pred_name = self.le.inverse_transform([pred_class])[0]
    confidence = prob[pred_class]

    return pred_name, confidence, box

try :
  drive.mount('/content/drive')
  print(f"Initializing Model ...\n")
  model = FaceRecognitionDemo2(model_path)

  print(f"Getting test images ready...\n")
  test_images = get_random_test_images(dataset_path)

  print(f"Making Predictions ...\n")
  predictions = []
  for _, img in test_images :
    pred_label, confidence, box = model.predict(img)
    predictions.append((pred_label, confidence, box))

  print(f"Displaying Results ...\n")
  display_results(test_images, predictions)

  for (t,_), (p, confidence,_) in zip(test_images, predictions) :
    if p is not None :
      if t == p :
        print(f"✓ True : {t:<20} Predicted : {p:<20} Confidence : {confidence : .2%}")
      else :
        print(f"✗ True : {t:<20} Predicted : {p:<20} Confidence : {confidence : .2%}")

    else :
      print(f"✗ True : {t:<20} No face Detected")

except Exception as e :
  print(f"An error occurred : {str(e)}")
  raise